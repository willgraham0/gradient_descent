# Gradient Descent

## Introduction

Gradient descent is the process of iteratively modifying
the variables of a function in a way that causes the error
between the output of the function and an existing answer to
be minimised the fastest for a particular input - we are
travelling down the 'error surface' by the steepest slope.  

## Functions

### Normal Distribution

![results_mu_sig_i10_r50]

![cost_contours_mu_sig_i10_r50]

![results_mu_sig_i10_r5]

![cost_contours_mu_sig_i10_r5]

![results_mu_sig_i10_r120]

![cost_contours_mu_sig_i10_r120]

![results_mu_sig_i100_r5]

![cost_contours_mu_sig_i100_r5]

### Linear Function

![results_m_c_i1000_r0.0001]

![cost_contours_m_c_i1000_r0.0001]

![results_m_c_i50_r0.01]

![cost_contours_m_c_i50_r0.01]

## Conclusion

[cost_contours_mu_sig_i10_r5]: images/cost_contours_mu_sig_i10_r5.png "cost_contours_mu_sig_i10_r5"
[cost_contours_mu_sig_i10_r50]: images/cost_contours_mu_sig_i10_r50.png "cost_contours_mu_sig_i10_r50"
[cost_contours_mu_sig_i10_r120]: images/cost_contours_mu_sig_i10_r120.png "cost_contours_mu_sig_i10_r120"
[cost_contours_mu_sig_i100_r5]: images/cost_contours_mu_sig_i100_r5.png "cost_contours_mu_sig_i100_r5"
[cost_contours_m_c_i50_r0.01]: images/cost_contours_m_c_i50_r0.01.png "cost_contours_m_c_i50_r0.01"
[cost_contours_m_c_i1000_r0.0001]: images/cost_contours_m_c_i1000_r0.0001.png "cost_contours_m_c_i1000_r0.0001"
[results_mu_sig_i10_r5]: images/results_mu_sig_i10_r5.png "results_mu_sig_i10_r5"
[results_mu_sig_i10_r50]: images/results_mu_sig_i10_r50.png "results_mu_sig_i10_r50"
[results_mu_sig_i10_r120]: images/results_mu_sig_i10_r120.png "results_mu_sig_i10_r120"
[results_mu_sig_i100_r5]: images/results_mu_sig_i100_r5.png "results_mu_sig_i100_r5"
[results_m_c_i50_r0.01]: images/results_m_c_i50_r0.01.png "results_m_c_i50_r0.01"
[results_m_c_i1000_r0.0001]: images/results_m_c_i1000_r0.0001.png "results_m_c_i1000_r0.0001"
